{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计学习笔记（01）：监督学习的主要概念\n",
    "2020-01-30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 监督学习的基本概念  \n",
    "监督学习（supervised learning）是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入和输出的对应关系，预测模型对给定的输入产生相应地输出。监督学习的本质是学习输入到输出的映射的统计规律。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 输入空间与输出空间  \n",
    "监督学习中，将输入与输出所有可能取值的集合称为输入空间和输出空间，每个输入是一个实例，通常由特征向量表示。输入和输出是定义在输入（特征）空间与输出空间上的随机变量的取值。  \n",
    "输入、输出变量用大写字母表示（如 $X$ 和 $Y$），输入、输出变量的**取值**用小写字母表示（如 $x$ 和 $y$）。输入实例 $x_i$ 的特征向量记作：$$x_i = \t\\left(x_i^1,x_i^2, \\cdots, x_i^n \\right)$$ $x_i$表示 $X$ 的第 $i$ 个特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习从训练数据（training data）集合中学习模型，对测试数据（test data）进行预测。训练数据由输入（特征向量）和输出对组成，表示为 $$T= \\left \\{(x_1,y_1), (x_2,y_2), \\cdots, (x_N,y_N)\\right \\}$$ 也称为样本（点）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入变量和输出变量均为连续变量的预测问题称为**回归问题**；输出变量为有限个离散变量的预测问题称为**分类问题**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 联合概率分布假设\n",
    "\n",
    "监督学习假设输入与输出的随机变量 $X$ 和 $Y$ 遵循联合概率分布 $P(X, Y)$，$P(X, Y)$ 表示分布函数或分布密度函数。统计学习假设数据存在一定的统计规律， $X$ 和 $Y$ 具有联合概率分布是监督学习关于数据的基本假设。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "联合概率分布：假设在**同一个实验中**有两个随机变量 $X$ 和 $Y$，设 $(x,y)$ 是 $X$ 和 $Y$ 的可能取值，则定义 $X$ 和 $Y$ 的联合概率是事件 $\\{X=x,Y=y\\}$ 的概率：$$p_{X,Y}(x,y) = P(\\{X=x\\}\\cap \\{Y=y\\}) = P(X=x, Y=y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 贝叶斯估计 与 极大似然估计\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯估计：假设随机变量 $D$ 表示数据，随机变量 $\\theta$ 表示模型参数，根据贝叶斯定理，后验概率 $P(\\theta \\vert D)$ 的计算方式是： \n",
    "$$P(\\theta \\vert D) = \\frac{P(\\theta)P(D \\vert \\theta)}{P(D)}$$  其中 $P(\\theta)$ 是先验概率，$P(D \\vert \\theta)$ 是似然函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上等式也说明，贝叶斯估计与极大似然估计是相互联系的，假设先验分布是均匀分布，取后验概率最大，即等从贝叶斯估计推导到极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "极大似然估计：假设一组随机变量 $X=\\{x_1, x_2, \\cdots, x_n\\}$ 服从概率分布 $x_i \\sim g_{\\theta}(x)$，$\\theta$ 表示一个或多个未知的决定 $X$ 分布的参数．这称为 $X$ 的参数模型。则定义似然函数：$$L(\\theta;X) = \\prod_{i=1}^N g_{\\theta}(x_i)$$ 这是观测数据在模型 $g_{\\theta}$ 下的概率（$x_i$ 相互独立），也就是将 $L(\\theta;X)$ 看作是 $X$ 确定时关于 $\\theta$ 的函数。$L(\\theta;X)$ 取对数就是 $$\\mathscr{l}(\\theta;X) = \\sum_{i=1}^N \\mathscr{l}(\\theta;x_i) \\\\ = \\sum_{i=1}^N \\log g_{\\theta}(x_i) $$ 以上可以简记为 $\\mathscr{l}(\\theta)$ 每个值 $\\mathscr{l}(\\theta;x_i)$ 称为对数似然组分．极大似然估计选择 $\\theta = \\hat{\\theta}$ 来最大化 $\\mathscr{l}(\\theta;X)$ ,具体方法是定义一个得分函数 $$\\dot{\\mathscr{l}}(\\theta;X) = \\sum_{i=1}^N \\dot{\\mathscr{l}}(\\theta;x_i)$$，其中 $$\\dot{\\mathscr{l}}(\\theta;x_i) = \\frac{\\partial \\mathscr{l}(\\theta;x_i)}{\\partial \\theta}$$ 假设概率在参数空间的内部取得最大值，则 $\\dot{\\mathscr{l}}(\\theta;X) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 学习方法的三要素\n",
    "\n",
    "方法 = 模型 + 策略 + 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**模型**：所要学习的条件概率分布或决策函数，模型的假设空间包含所有可能的条件概率分布或决策函数，假设空间用 $\\mathscr{F}$ 表示，如果是决策函数，可以表示为：$$\\mathscr{F} = \\{f \\vert Y = f_{\\theta}(X), \\theta \\in R^n\\}$$ 参数向量 $\\theta$ 取值于 $n$ 维欧式空间 $R^n$ ，称为参数空间（parameter space）；如果是条件概率的集合，$\\mathscr{F}$ 是由一个参数向量决定的条件概率分布族：$$\\mathscr{F} = \\{P \\vert P_{\\theta}(Y \\vert X),\\theta \\in R^n \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习方法可以分为生成方法（generative approach）和判别方法（discriminative approach）.  \n",
    "**生成方法**由数据学习联合概率分布 $P(X,Y)$，然后求出条件概率分布 $P(Y \\vert X)$ 作为预测的模型，即生成模型：$$P(Y \\vert X) = \\frac{P(X,Y)}{P(X)}$$ 生成方法可以还原出联合概率分布 $P(X,Y)$，学习收敛更快。  \n",
    "**判别方法**由数据直接学习决策函数 $f(X)$ 或者条件概率分布 $P(Y \\vert X)$ 作为预测的模型，判别方法关心的是对给定的输入 $X$ 应该预测什么样的输出 $Y$。判别方法直接面对预测，往往学习的准确率更高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**策略**：即按照什么样的准则学习或选择最优的模型，主要方法是利用损失函数或风险函数。\n",
    "> * 损失函数：度量模型一次预测的好坏\n",
    "> * 风险函数：度量平均意义下模型预测的好坏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 期望损失 和 经验损失\n",
    "损失函数是 $f(X)$ 和 $Y$ 的非负实值函数，记作 $L(Y, f(X))$。常用损失函数有：\n",
    "* 0-1 损失函数 \n",
    "$$ L(Y, f(X))=\\left\\{\n",
    "\\begin{aligned}\n",
    "1,\\;\\; Y\\neq f(X)\\\\\n",
    "0,\\;\\; Y= f(X)\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$   \n",
    "* 平方损失函数（quadratic loss function） $$L(Y, f(X))=(Y-f(X))^2$$\n",
    "* 绝对损失函数（absolute loss function） $$L(Y, f(X))=\\vert Y-f(X)\\vert$$\n",
    "* 对数损失函数（logarithmic loss function） $$L(Y, f(X))= - \\log P(Y \\vert X)$$\n",
    "\n",
    "损失函数越小，模型就越好。由于模型的输入和输出 $(X,Y)$ 是随机变量，遵循联合概率分布 $P(X,Y)$ ，所以损失函数的期望是 $$\t\\begin{equation}\n",
    "\t\t\\begin{split}\n",
    "\t\t& R_{exp} = E_{p}[L(Y, f(X))]\\\\\n",
    "\t\t& = \\int_{\\mathscr{X} \\times \\mathscr{Y}}L(y,f(x))P(x,y)dxdy\n",
    "\t\t\\end{split}\n",
    "\t\\end{equation}$$\n",
    "这是理论上模型 $f(X)$ 关于联合分布 $P(X,Y)$ 的平均意义下的损失，称为风险函数（risk function）或期望损失（expected loss）。  \n",
    "由于联合分布  $P(X,Y)$ 不能直接计算，$R_{exp}$ 也无法直接计算出，因此只能通过观测到的训练数据集来计算经验风险。模型 $f(X)$ 关于训练数据集的平均损失称为经验风险（empirical risk）或经验损失（empirical loss）：$$R_{emp} = \\frac{1}{N} \\sum_{i=1}^N L(y_i,f(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 模型选择：经验风险最小化 和 结构风险最小化\n",
    "根据[大数定律](https://www.zhihu.com/question/19911209/answer/876481176)，当样本容量 $N$ 趋近无穷时，经验风险 $R_{emp}$ 趋于期望风险 $R_{exp}$。所以可以用经验风险估计期望风险。但由于现实中训练样本数目有限甚至很小，所以用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正。监督学习有两个基本策略：经验风险最小化和结构风险最小化。  \n",
    "经验风险最小化（empirical risk minimization, ERM）认为经验风险最小的模型就是最优模型，根据这一策略，按照经验风险最小化求最优模型就是求解最优化问题： $$\\min_{f \\in \\mathscr{F}} \\frac{1}{N} \\sum_{i=1}^{N}L(y_i,f(x_i))$$ 但这种方法当样本容量很小时，会产生**过拟合**（over-fitting）问题。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当假设空间含有不同复杂度（如不同的参数个数）的模型时，就要面临模型选择（model selection）的问题，我们希望选择或学习一个合适的模型，如果假设空间中存在“真”模型，所选择的模型要与真模型的参数个数相同，参数向量要与真模型的参数向量相近。  \n",
    "但一味追求提高对训练数据的预测能力，所选择模型的复杂度往往会比真模型高，这种现象称为过拟合（over-fitting）。**过拟合**是指学习时选择的模型所包含的参数过多。导致出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 下图来自李航《统计学习方法》\n",
    "![overfitting](PICS\\over-fitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 正则化\n",
    "结构风险最小化（structural risk minimization，SRM）是为了防止过拟合而提出的策略，等价于正则化（regularization），即在经验风险上加上表示模型复杂度的正则化项（regularizer）或罚项（penalty term）：$$R_{srm} = \\frac{1}{N} \\sum_{i=1}^{N}L(y_i,f(x_i)) + \\lambda J(f)$$  结构风险最小化的策略认为结构风险最小的模型就是最优的模型，所以求解最优模型就是求解最优化问题：$$\\min_{f \\in \\mathscr{F}} \\Big(\\frac{1}{N} \\sum_{i=1}^{N}L(y_i,f(x_i)) + \\lambda J(f)\\Big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 交叉验证\n",
    "如果给定的样本充足，进行模型选择的一种简单方法是随机地将数据切分为三部分：分为训练集（training set）、验证集（validation set）和测试集（test set）。训练集用来训练模型，验证集用于模型的选择，而测试集用于最终对学习方法的评估。在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型，由于验证集有足够多的数据，用它对模型进行选择也是有效的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但在许多实际应用中数据是不充足的，为了选择好的模型，可以采用**交叉验证**（cross validation）方法，交叉验证的基本想法是重复地使用数据：把给定的数据进行切分，将切分的数据集组合为训练集和测试集。\n",
    "* **简单交叉验证**：随机地将已给的数据分为两部分，一部分作为训练集，另一部分作为测试集；然后用训练集在各种条件下训练模型，从而得到不同模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。\n",
    "* **$S$ 折交叉验证**（S-fold cross validation）：首先随机地将已给数据切分为 $S$ 个互不相交、大小相同的子集；然后利用 $S-1$ 个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的 $S$ 种选择重复进行；最后选出 $S$ 次评测中平均测试误差最小的模型。\n",
    "* 留一交叉验证：$S$ 折交叉验证的特殊情况是 $S=N$，称为留一交叉验证（leave-one-out cross validation），往往在数据缺乏的情况下使用。$N$ 是给定数据集的容量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 模型的泛化能力\n",
    "学习方法的泛化能力（generalization ability）是指该学习方法学习到的模型对未知数据的预测能力。现实中采用最多的办法是通过测试误差来评价学习方法的泛化能力，但这种评价方法是依赖于测试数据集的，而由于测试数据是有限的，因此得到的评价结果是不可靠的。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "泛化误差：如果学习到的模型是 $\\hat{f}$，那么用这个模型对未知数据预测的误差就是泛化误差（generalization error）：\n",
    "$$R_{exp} = E_p[L(Y,\\hat{f}(X)] = \\int_{\\mathscr{X} \\times \\mathscr{Y}}L(y,\\hat{f}(x))P(x,y)dxdy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称泛化误差上界（generalization error bound）。具体来说就是通过比较两种学习方法的泛化误差上界的大小来比较它们的优劣。    \n",
    "泛化误差上界通常具有以下性质：它是样本容量的函数，当样本容量增加时，泛化上界趋于0；它是假设空间容量（capacity）的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分类问题中的精度指标  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 准确率、精确率、召回率\n",
    "分类问题有不同角度的指标衡量模型的效果。以二分类为例，对于分类问题中模型判别的结果有以下四种："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| 实际为正例（positive） | 实际为负例（negative） | \n",
    "| :------: | :------: |  :------: | \n",
    "|**判别为正例（positive）**|真正例（true positive） |假正例（false positive） |\n",
    "|**判别为负例（negative）**|假负例（false negative） | 真负例（true negative）  | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用以上分类结果的大写字母缩写代表数量，可以定义准确率、精确率、召回率等：  \n",
    "**准确率**（accuracy）表示分类器给出的正确结果的比例：$$\\text{accuracy} = \\frac{TP + TN}{TP + FP + FP +FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**精确率**（precision，也成查准率）表示被判断正确的正例数量（TP）占模型所有判别为正例数量的比例：\n",
    "$$\\text{precision} = \\frac{TP}{TP+FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**召回率**（recall，也成查全率）表示被判断正确的正例数量（TP）占样本中真正正例（TP + FN）的比例：\n",
    "$$\\text{recall} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精确率和召回率在某种程度上是反向相关的（因为如果FP数量增加，则FN的数量就会减少），它们可以结合起来给出一个单一的度量 $F_1$ 值（即precision和recall的调和均值）：\n",
    "$$F_1 = 2 \\times \\frac{precision \\times recall}{precision + recall}$$ 也就相当于对模型判断为假的实例数量取了均值：\n",
    "$$F_1 = \\frac{TP}{TP + (FP + FN)/2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 下图来自《机器学习与优化》\n",
    "![acc_pre_rec](PICS\\acc_per_rec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ROC曲线 与 AUC\n",
    "比较不同预测分类的模型时，受试者工作特征曲线（receiver operating characteristic curve，简称ROC曲线）及其AUC（曲线下面积，Area Under Curve）常被用以评价模型效果。ROC曲线的纵轴为召回率（也称为“真正例率”），横轴为“假正例率”，伪阳率的计算方式是：$$FPRate = \\frac{FP}{FP+TN}$$  \n",
    "根据模型的预测结果对实例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横纵坐标，就得到了ROC曲线。给定 $m^+$ 个正例和 $m^-$ 个负例，根据模型预测结果对实例进行排序，然后将分类阈值设为最大，即把所有实例预测为负例，此时真正例率和假正例率均为0，在坐标 $(0,0)$ 处标记一个点，然后，将分类阈值依次设为每个实例的预测值，即依次将每个实例划分为正例，设前一个标记点坐标为 $(x,y)$ ，当前若为真正例，则对应标记点的坐标为 $(x,y + \\frac{1}{m^+})$，若当前为假正例，则对应标记点的坐标为 $(x + \\frac{1}{m^-},y)$，然后用线段连接相邻点即得。\n",
    "* 下图来自西瓜书\n",
    "![auc_roc](PICS\\auc_roc.png)  \n",
    "\n",
    "对角线代表随机猜测，所以线上方的任何模型表现都比随机性好，且距离对角线越远越好。分类模型希望达到的效果是：对于真实类别为正例的样本，分类器预测为正例的概率（即真正例率），要大于真实类别为负例而预测类别为正例的概率（即假正例率）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 参考资料：\n",
    "* [统计学习方法（第二版）](https://book.douban.com/subject/33437381/)\n",
    "* [机器学习](https://book.douban.com/subject/26708119/)\n",
    "* [概率导论（第2版·修订版）](https://book.douban.com/subject/26694188/)\n",
    "* [机器学习：算法视角](https://book.douban.com/subject/33397324/)\n",
    "* [机器学习与优化](https://book.douban.com/subject/30239753/)\n",
    "* [ESL-CN：8.2 自助法和最大似然法](https://esl.hohoweiya.xyz/08-Model-Inference-and-Averaging/8.2-The-Bootstrap-and-Maximum-Likelihood-Methods/index.html)\n",
    "* [知乎：如何理解机器学习和统计中的AUC？——无涯的回答](https://www.zhihu.com/question/39840928/answer/241440370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "341.2px",
    "left": "778px",
    "top": "210.8px",
    "width": "204.8px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
