{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#统计学习笔记（03）：线性回归\" data-toc-modified-id=\"统计学习笔记（03）：线性回归-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>统计学习笔记（03）：线性回归</a></span><ul class=\"toc-item\"><li><span><a href=\"#线性回归模型\" data-toc-modified-id=\"线性回归模型-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>线性回归模型</a></span></li><li><span><a href=\"#正态分布\" data-toc-modified-id=\"正态分布-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>正态分布</a></span></li><li><span><a href=\"#最小二乘法\" data-toc-modified-id=\"最小二乘法-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>最小二乘法</a></span></li><li><span><a href=\"#正则化\" data-toc-modified-id=\"正则化-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>正则化</a></span></li><li><span><a href=\"#参考资料：\" data-toc-modified-id=\"参考资料：-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>参考资料：</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计学习笔记（03）：线性回归\n",
    "---\n",
    "**2020-02-07**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线性回归模型\n",
    "\n",
    "线性回归的基本形式是，给定 $N$ 个由 $p$ 维特征（属性）描述的实例 $x_i = (x_i^1, x_i^2, \\cdots, x_i^p), i = 1,2,\\cdots,N$，并且对每一个实例都有对应的 $y_i$ 作为标签的取值，训练数据为 $\\left \\{(x_1,y_1), (x_2,y_2), \\cdots, (x_N,y_N)\\right \\}$，线性回归模型试图学得一个通过特征**线性组合**来进行预测的函数：$$y_i = w_1 x_i^1 + w_2 x_i^2 + \\cdots + w_p x_i^p + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用矩阵形式来描述线性回归模型，$x_i$ 所对应的特征值是一个 $p$ 维的列向量，$y_i$ 是一个实数，则设 $X = (x_1, x_2, \\cdots, x_N)^T$ （使得矩阵的每一行是一个实例），$Y = (y_1, y_2, \\cdots, y_N)$ ，则线性回归模型可以表示为：$$Y = XW + b$$，其中 $b \\in R^N$ 称为**偏置**（偏移项）。这里，$$X = \\begin{pmatrix}\n",
    "    x_1^1 & x_1^2 & \\cdots & x_1^p\\\\\n",
    "    x_2^1 & x_2^2 & \\cdots & x_2^p\\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "    x_N^1 & x_N^2 & \\cdots & x_N^p\\\\\n",
    "\\end{pmatrix} \\;\\;\\;\\;\\;\\;Y = \\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2\\\\\n",
    "\\cdots \\\\\n",
    "y_N\n",
    "\\end{pmatrix} \\;\\;\\;\\;\\;\\; W = \\begin{pmatrix}\n",
    "w_1 \\\\\n",
    "w_2\\\\\n",
    "\\cdots \\\\\n",
    "w_p\n",
    "\\end{pmatrix} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为更简便表示，可以将 $b$ 合并到 $W$ 中，在 $X$ 中增加一个特征值 $x_i^0 = 1$，表示为：$$Y = X W$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归中使用了正态分布的假设来进行参数估计，故首先对正态分布做梳理。  \n",
    "正态分布是一个概率密度函数，表达式是：$$P(x) = \\frac{1}{\\sqrt{2 \\pi}\\sigma} \\exp \\Big(- \\frac{(x - \\mu)^2}{2\\sigma^2} \\Big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 最小二乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归的损失函数是 $$\\mathscr{L}(w) =\\frac{1}{N} \\sum_{i=1}^N  \\Vert XW -Y \\Vert^2 =\\frac{1}{N} \\sum_{i=1}^N (w^T x_i - y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最小二乘法有两个前提假设：\n",
    "* 对每个样本 $(x_i, y_i)$，线性回归模型的预测值 $w^Tx_i$ 和真实值 $y_i$ 之间的关系是 $y_i = w^Tx_i + \\epsilon_i$，$\\epsilon_i$ 表示预测值与真实值之间的误差；\n",
    "* $\\epsilon_i$ 是一组独立同分布的随机变量，服从正态分布 $\\epsilon \\sim N(0,\\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 参考资料： \n",
    "* [shuhuai008](https://github.com/shuhuai007/Machine-Learning-Session)：[机器学习-白板推导系列-合集](https://www.bilibili.com/video/av70839977)\n",
    "* [线性模型—— 一元线性回归算法推导](https://www.jianshu.com/p/59283c35d622)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
